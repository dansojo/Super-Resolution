{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Q1gjrXrlZAvaP8hcoepi6C8hBWNogd6p",
      "authorship_tag": "ABX9TyOI6ujHO7+YfL+WHm8OeajA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dansojo/Super-Resolution/blob/main/FSRCNN_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FSRCNN (Fast Super-Resolution Convolutional Neural Network)"
      ],
      "metadata": {
        "id": "oQV-ExAH4NCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.image as img\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "OGdgaN1I4Y1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(lr_directory, hr_directory, target_size=(512, 512)):\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "\n",
        "    # 파일 목록을 안전하게 가져오기\n",
        "    try:\n",
        "        lr_filenames = sorted(os.listdir(lr_directory))\n",
        "        hr_filenames = sorted(os.listdir(hr_directory))\n",
        "    except FileNotFoundError:\n",
        "        print(\"Directory not found\")\n",
        "        return [], []\n",
        "\n",
        "    for lr_file, hr_file in zip(lr_filenames, hr_filenames):\n",
        "        try:\n",
        "            lr_image_path = os.path.join(lr_directory, lr_file)\n",
        "            hr_image_path = os.path.join(hr_directory, hr_file)\n",
        "\n",
        "            lr_img = Image.open(lr_image_path).resize(target_size, Image.BICUBIC)\n",
        "            hr_img = Image.open(hr_image_path).resize((2048, 2048), Image.BICUBIC)\n",
        "\n",
        "            x_train.append(np.array(lr_img))\n",
        "            y_train.append(np.array(hr_img))\n",
        "        except (IOError, OSError):\n",
        "            print(f\"Error processing {lr_file} or {hr_file}\")\n",
        "\n",
        "    if len(x_train) > 0 and len(y_train) > 0:\n",
        "        x_train = np.array(x_train) / 255.0\n",
        "        y_train = np.array(y_train) / 255.0\n",
        "\n",
        "    return x_train, y_train"
      ],
      "metadata": {
        "id": "SzYVs83bLaZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FSRCNN(scale_factor, num_channels=1, d=56, s=12, m=4):\n",
        "    # Input layer\n",
        "    input_layer = Input(shape=(None, None, num_channels), name='input_layer')\n",
        "\n",
        "    # Feature extraction\n",
        "    x = Conv2D(d, (5, 5), padding='same', activation='relu', name='feature_extraction')(input_layer)\n",
        "\n",
        "    # Shrinking\n",
        "    x = Conv2D(s, (1, 1), padding='same', activation='relu', name='shrinking')(x)\n",
        "\n",
        "    # Non-linear mapping\n",
        "    for i in range(m):\n",
        "        x = Conv2D(s, (3, 3), padding='same', activation='relu', name=f'non_linear_mapping_{i+1}')(x)\n",
        "\n",
        "    # Expanding\n",
        "    x = Conv2D(d, (1, 1), padding='same', activation='relu', name='expanding')(x)\n",
        "\n",
        "    # Deconvolution\n",
        "    x = Conv2D(num_channels, (9, 9), strides=(scale_factor, scale_factor), padding='same', activation='linear', name='reconstruction')(x)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=input_layer, outputs=x)\n",
        "    return model"
      ],
      "metadata": {
        "id": "l7M696AG4Ps8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터셋 로드 경로\n",
        "dataset_hr_directory = '/content/drive/MyDrive/Super-Resolution/SR_data_set/train/hr'\n",
        "dataset_lr_directory = '/content/drive/MyDrive/Super-Resolution/SR_data_set/train/lr'\n",
        "x_train, y_train = load_images(dataset_lr_directory, dataset_hr_directory)"
      ],
      "metadata": {
        "id": "n-nFozA0OIj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYBtbBRx3qPj"
      },
      "outputs": [],
      "source": [
        "# Create the FSRCNN model\n",
        "scale_factor = 4  # Example scale factor\n",
        "fsrcnn_model = FSRCNN(scale_factor=scale_factor)\n",
        "\n",
        "# Compile the model\n",
        "fsrcnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "fsrcnn_model.fit(x_train, y_train, batch_size=16, epochs=100)\n",
        "\n",
        "# After training, you might want to save the model or visualize the results\n",
        "fsrcnn_model.save('fsrcnn_model_v1.h5')\n"
      ]
    }
  ]
}
